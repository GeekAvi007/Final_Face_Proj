{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f24e5b06",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mtcnn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmtcnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MTCNN\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Connect to SQLite database\u001b[39;00m\n\u001b[0;32m      8\u001b[0m conn \u001b[38;5;241m=\u001b[39m sqlite3\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfaces.db\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mtcnn'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from mtcnn import MTCNN\n",
    "\n",
    "# Connect to SQLite database\n",
    "conn = sqlite3.connect('faces.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "# Create table to store faces if not exists\n",
    "c.execute('''CREATE TABLE IF NOT EXISTS faces\n",
    "             (name TEXT, embedding TEXT)''')\n",
    "conn.commit()\n",
    "\n",
    "# Load pre-trained MTCNN for face detection\n",
    "detector = MTCNN()\n",
    "\n",
    "# Load pre-trained FaceNet model for face recognition\n",
    "facenet_model = load_model('facenet_keras.h5')\n",
    "\n",
    "# Function to draw rectangle around face and display name\n",
    "def draw_name_and_border(frame, x, y, w, h, name):\n",
    "    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 255), 2)  # Yellow rectangle around face\n",
    "    cv2.putText(frame, name, (x, y + h + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)  # Name below face\n",
    "\n",
    "# Function to register a new face\n",
    "def register_face(name, embedding):\n",
    "    c.execute(\"INSERT INTO faces (name, embedding) VALUES (?, ?)\", (name, embedding))\n",
    "    conn.commit()\n",
    "\n",
    "# Function to recognize face\n",
    "def recognize_face(face):\n",
    "    face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "    face = cv2.resize(face, (160, 160))  # Resize image for FaceNet input\n",
    "    face = face / 255.0  # Normalize pixel values\n",
    "\n",
    "    # Extract face embedding using FaceNet model\n",
    "    embedding = facenet_model.predict(np.expand_dims(face, axis=0))[0]\n",
    "\n",
    "    # Compare face embedding with embeddings in the database\n",
    "    c.execute(\"SELECT name, embedding FROM faces\")\n",
    "    for row in c.fetchall():\n",
    "        saved_embedding = np.fromstring(row[1], dtype=float, sep=',')\n",
    "        distance = np.linalg.norm(embedding - saved_embedding)\n",
    "        if distance < 0.7:  # Set threshold for similarity\n",
    "            return row[0]\n",
    "    return None\n",
    "\n",
    "# Main loop for face recognition\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    faces = detector.detect_faces(frame)\n",
    "    for face in faces:\n",
    "        x, y, w, h = face['box']\n",
    "        name = recognize_face(frame[y:y+h, x:x+w])\n",
    "        if name:\n",
    "            draw_name_and_border(frame, x, y, w, h, name)\n",
    "\n",
    "    cv2.imshow('Face Recognition', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d1f94d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mtcnn\n",
      "  Downloading mtcnn-0.1.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: keras>=2.0.0 in c:\\users\\avish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mtcnn) (2.12.0)\n",
      "Requirement already satisfied: opencv-python>=4.1.0 in c:\\users\\avish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mtcnn) (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\avish\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opencv-python>=4.1.0->mtcnn) (1.23.5)\n",
      "Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/2.3 MB 991.0 kB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.2/2.3 MB 1.7 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.4/2.3 MB 2.9 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.7/2.3 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.0/2.3 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.5/2.3 MB 5.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.8/2.3 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.8/2.3 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.8/2.3 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.8/2.3 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.8/2.3 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.8/2.3 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.8/2.3 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.8/2.3 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.8/2.3 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.8/2.3 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.8/2.3 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.8/2.3 MB 2.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.8/2.3 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.8/2.3 MB 2.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.9/2.3 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.9/2.3 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.0/2.3 MB 1.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.2/2.3 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.3 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.3/2.3 MB 1.8 MB/s eta 0:00:00\n",
      "Installing collected packages: mtcnn\n",
      "Successfully installed mtcnn-0.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c6e3a45",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at facenet_keras.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m detector \u001b[38;5;241m=\u001b[39m MTCNN()\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Load pre-trained FaceNet model for face recognition\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m facenet_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfacenet_keras.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Function to draw rectangle around face and display name\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_name_and_border\u001b[39m(frame, x, y, w, h, name):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\saving\\saving_api.py:212\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    205\u001b[0m         filepath,\n\u001b[0;32m    206\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    207\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[0;32m    208\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[0;32m    209\u001b[0m     )\n\u001b[0;32m    211\u001b[0m \u001b[38;5;66;03m# Legacy case.\u001b[39;00m\n\u001b[1;32m--> 212\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_sm_saving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\saving\\legacy\\save.py:230\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_str, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(filepath_str):\n\u001b[1;32m--> 230\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[0;32m    231\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo file or directory found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    232\u001b[0m         )\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(filepath_str):\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_load\u001b[38;5;241m.\u001b[39mload(\n\u001b[0;32m    236\u001b[0m             filepath_str, \u001b[38;5;28mcompile\u001b[39m, options\n\u001b[0;32m    237\u001b[0m         )\n",
      "\u001b[1;31mOSError\u001b[0m: No file or directory found at facenet_keras.h5"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from mtcnn import MTCNN\n",
    "\n",
    "# Connect to SQLite database\n",
    "conn = sqlite3.connect('faces.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "# Create table to store faces if not exists\n",
    "c.execute('''CREATE TABLE IF NOT EXISTS faces\n",
    "             (name TEXT, embedding TEXT)''')\n",
    "conn.commit()\n",
    "\n",
    "# Load pre-trained MTCNN for face detection\n",
    "detector = MTCNN()\n",
    "\n",
    "# Load pre-trained FaceNet model for face recognition\n",
    "facenet_model = load_model('facenet_keras.h5')\n",
    "\n",
    "# Function to draw rectangle around face and display name\n",
    "def draw_name_and_border(frame, x, y, w, h, name):\n",
    "    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 255), 2)  # Yellow rectangle around face\n",
    "    cv2.putText(frame, name, (x, y + h + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)  # Name below face\n",
    "\n",
    "# Function to register a new face\n",
    "def register_face(name, embedding):\n",
    "    c.execute(\"INSERT INTO faces (name, embedding) VALUES (?, ?)\", (name, embedding))\n",
    "    conn.commit()\n",
    "\n",
    "# Function to recognize face\n",
    "def recognize_face(face):\n",
    "    face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "    face = cv2.resize(face, (160, 160))  # Resize image for FaceNet input\n",
    "    face = face / 255.0  # Normalize pixel values\n",
    "\n",
    "    # Extract face embedding using FaceNet model\n",
    "    embedding = facenet_model.predict(np.expand_dims(face, axis=0))[0]\n",
    "\n",
    "    # Compare face embedding with embeddings in the database\n",
    "    c.execute(\"SELECT name, embedding FROM faces\")\n",
    "    for row in c.fetchall():\n",
    "        saved_embedding = np.fromstring(row[1], dtype=float, sep=',')\n",
    "        distance = np.linalg.norm(embedding - saved_embedding)\n",
    "        if distance < 0.7:  # Set threshold for similarity\n",
    "            return row[0]\n",
    "    return None\n",
    "\n",
    "# Main loop for face recognition\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    faces = detector.detect_faces(frame)\n",
    "    for face in faces:\n",
    "        x, y, w, h = face['box']\n",
    "        name = recognize_face(frame[y:y+h, x:x+w])\n",
    "        if name:\n",
    "            draw_name_and_border(frame, x, y, w, h, name)\n",
    "\n",
    "    cv2.imshow('Face Recognition', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4e9e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
